Epoch: 0  Training Loss: 1.9330317974090576  Training Accuracy: 0.30767902731895447
Epoch: 0  Validation Loss: 1.738936424255371  Validation Accuracy: 0.4099999964237213
Epoch: 1  Training Loss: 1.7905092239379883  Training Accuracy: 0.3624098598957062
Epoch: 1  Validation Loss: 1.6688685417175293  Validation Accuracy: 0.42640000581741333
Epoch: 2  Training Loss: 1.7401281595230103  Training Accuracy: 0.3824814558029175
Epoch: 2  Validation Loss: 1.6590380668640137  Validation Accuracy: 0.448199987411499
Epoch: 3  Training Loss: 1.7057876586914062  Training Accuracy: 0.39514076709747314
Epoch: 3  Validation Loss: 1.6033351421356201  Validation Accuracy: 0.46720001101493835
Epoch: 4  Training Loss: 1.6767821311950684  Training Accuracy: 0.405671626329422
Epoch: 4  Validation Loss: 1.5941824913024902  Validation Accuracy: 0.46639999747276306
Epoch: 5  Training Loss: 1.6576530933380127  Training Accuracy: 0.4123876690864563
Epoch: 5  Validation Loss: 1.5626238584518433  Validation Accuracy: 0.4729999899864197
Epoch: 6  Training Loss: 1.6392215490341187  Training Accuracy: 0.4194074273109436
Epoch: 6  Validation Loss: 1.551972508430481  Validation Accuracy: 0.4828000068664551
Epoch: 7  Training Loss: 1.6223026514053345  Training Accuracy: 0.42577528953552246
Epoch: 7  Validation Loss: 1.5462331771850586  Validation Accuracy: 0.47780001163482666
Epoch: 8  Training Loss: 1.6061630249023438  Training Accuracy: 0.42766666412353516
Epoch: 8  Validation Loss: 1.5407644510269165  Validation Accuracy: 0.487199991941452
Epoch: 9  Training Loss: 1.6006273031234741  Training Accuracy: 0.43406665325164795
Epoch: 9  Validation Loss: 1.526075005531311  Validation Accuracy: 0.4893999993801117
Epoch: 10  Training Loss: 1.5844215154647827  Training Accuracy: 0.4381752908229828
Epoch: 10  Validation Loss: 1.4955483675003052  Validation Accuracy: 0.503000020980835
Epoch: 11  Training Loss: 1.577086091041565  Training Accuracy: 0.4388839304447174
Epoch: 11  Validation Loss: 1.5209133625030518  Validation Accuracy: 0.4952000081539154
Epoch: 12  Training Loss: 1.5609227418899536  Training Accuracy: 0.44655555486679077
Epoch: 12  Validation Loss: 1.4851226806640625  Validation Accuracy: 0.5123999714851379
Epoch: 13  Training Loss: 1.5566189289093018  Training Accuracy: 0.4462716281414032
Epoch: 13  Validation Loss: 1.5307486057281494  Validation Accuracy: 0.4918000102043152
Epoch: 14  Training Loss: 1.5477648973464966  Training Accuracy: 0.44474074244499207
Epoch: 14  Validation Loss: 1.5002232789993286  Validation Accuracy: 0.49939998984336853
Epoch: 15  Training Loss: 1.5393847227096558  Training Accuracy: 0.45326173305511475
Epoch: 15  Validation Loss: 1.4873348474502563  Validation Accuracy: 0.5067999958992004
Epoch: 16  Training Loss: 1.5308592319488525  Training Accuracy: 0.45613333582878113
Epoch: 16  Validation Loss: 1.4896397590637207  Validation Accuracy: 0.4973999857902527
Epoch: 17  Training Loss: 1.5271121263504028  Training Accuracy: 0.4556567668914795
Epoch: 17  Validation Loss: 1.4751616716384888  Validation Accuracy: 0.5103999972343445
Epoch: 18  Training Loss: 1.5238889455795288  Training Accuracy: 0.4580765664577484
Epoch: 18  Validation Loss: 1.4640837907791138  Validation Accuracy: 0.5149999856948853
Epoch: 19  Training Loss: 1.5102506875991821  Training Accuracy: 0.46300989389419556
Epoch: 19  Validation Loss: 1.482131004333496  Validation Accuracy: 0.49300000071525574
Epoch: 20  Training Loss: 1.5056475400924683  Training Accuracy: 0.4646790027618408
Epoch: 20  Validation Loss: 1.459593653678894  Validation Accuracy: 0.5077999830245972
Epoch: 21  Training Loss: 1.503164291381836  Training Accuracy: 0.46662965416908264
Epoch: 21  Validation Loss: 1.4629799127578735  Validation Accuracy: 0.49720001220703125
Epoch: 22  Training Loss: 1.491986632347107  Training Accuracy: 0.4657876789569855
Epoch: 22  Validation Loss: 1.454119324684143  Validation Accuracy: 0.5058000087738037
Epoch: 23  Training Loss: 1.4896172285079956  Training Accuracy: 0.47299009561538696
Epoch: 23  Validation Loss: 1.4625341892242432  Validation Accuracy: 0.5045999884605408
Epoch: 24  Training Loss: 1.4831736087799072  Training Accuracy: 0.4746493995189667
Epoch: 24  Validation Loss: 1.4615651369094849  Validation Accuracy: 0.4997999966144562
Epoch: 25  Training Loss: 1.4834964275360107  Training Accuracy: 0.4720296561717987
Epoch: 25  Validation Loss: 1.4624203443527222  Validation Accuracy: 0.5009999871253967
Epoch: 26  Training Loss: 1.4751091003417969  Training Accuracy: 0.4747728407382965
Epoch: 26  Validation Loss: 1.4557504653930664  Validation Accuracy: 0.506600022315979
Epoch: 27  Training Loss: 1.4690334796905518  Training Accuracy: 0.47377777099609375
Epoch: 27  Validation Loss: 1.4583300352096558  Validation Accuracy: 0.4973999857902527
Epoch: 28  Training Loss: 1.4669833183288574  Training Accuracy: 0.4803975224494934
Epoch: 28  Validation Loss: 1.456491231918335  Validation Accuracy: 0.5085999965667725
Epoch: 29  Training Loss: 1.4645246267318726  Training Accuracy: 0.47794076800346375
Epoch: 29  Validation Loss: 1.4627817869186401  Validation Accuracy: 0.503000020980835
Epoch: 30  Training Loss: 1.454533576965332  Training Accuracy: 0.48258519172668457
Epoch: 30  Validation Loss: 1.4507275819778442  Validation Accuracy: 0.5067999958992004
Epoch: 31  Training Loss: 1.4527117013931274  Training Accuracy: 0.48205676674842834
Epoch: 31  Validation Loss: 1.4430115222930908  Validation Accuracy: 0.49799999594688416
Epoch: 32  Training Loss: 1.4518457651138306  Training Accuracy: 0.4841580390930176
Epoch: 32  Validation Loss: 1.4372917413711548  Validation Accuracy: 0.5105999708175659
Epoch: 33  Training Loss: 1.448781132698059  Training Accuracy: 0.48082223534584045
Epoch: 33  Validation Loss: 1.4463584423065186  Validation Accuracy: 0.5012000203132629
Epoch: 34  Training Loss: 1.44334077835083  Training Accuracy: 0.48571357131004333
Epoch: 34  Validation Loss: 1.4370617866516113  Validation Accuracy: 0.5059999823570251
Epoch: 35  Training Loss: 1.4437886476516724  Training Accuracy: 0.48782965540885925
Epoch: 35  Validation Loss: 1.427241325378418  Validation Accuracy: 0.5130000114440918
Epoch: 36  Training Loss: 1.43294358253479  Training Accuracy: 0.49108394980430603
Epoch: 36  Validation Loss: 1.4366945028305054  Validation Accuracy: 0.5127999782562256
Epoch: 37  Training Loss: 1.4276773929595947  Training Accuracy: 0.49208641052246094
Epoch: 37  Validation Loss: 1.437865138053894  Validation Accuracy: 0.5148000121116638
Epoch: 38  Training Loss: 1.4309059381484985  Training Accuracy: 0.487888902425766
Epoch: 38  Validation Loss: 1.4568650722503662  Validation Accuracy: 0.5023999810218811
Epoch: 39  Training Loss: 1.428061842918396  Training Accuracy: 0.4904395043849945
Epoch: 39  Validation Loss: 1.4230501651763916  Validation Accuracy: 0.5181999802589417
Epoch: 40  Training Loss: 1.4214333295822144  Training Accuracy: 0.49439504742622375
Epoch: 40  Validation Loss: 1.4388093948364258  Validation Accuracy: 0.5139999985694885
Epoch: 41  Training Loss: 1.4175971746444702  Training Accuracy: 0.49322718381881714
Epoch: 41  Validation Loss: 1.4310444593429565  Validation Accuracy: 0.5123999714851379
Epoch: 42  Training Loss: 1.4104706048965454  Training Accuracy: 0.4997160732746124
Epoch: 42  Validation Loss: 1.4324991703033447  Validation Accuracy: 0.5188000202178955
Epoch: 43  Training Loss: 1.4101388454437256  Training Accuracy: 0.49665185809135437
Epoch: 43  Validation Loss: 1.4451467990875244  Validation Accuracy: 0.5063999891281128
Epoch: 44  Training Loss: 1.408650279045105  Training Accuracy: 0.4972222149372101
Epoch: 44  Validation Loss: 1.4252676963806152  Validation Accuracy: 0.5206000208854675
Epoch: 45  Training Loss: 1.4053077697753906  Training Accuracy: 0.5005308389663696
Epoch: 45  Validation Loss: 1.4352672100067139  Validation Accuracy: 0.5123999714851379
Epoch: 46  Training Loss: 1.4071357250213623  Training Accuracy: 0.4987432360649109
Epoch: 46  Validation Loss: 1.4330719709396362  Validation Accuracy: 0.5081999897956848
Epoch: 47  Training Loss: 1.397811770439148  Training Accuracy: 0.5012148022651672
Epoch: 47  Validation Loss: 1.4363737106323242  Validation Accuracy: 0.5192000269889832
Epoch: 48  Training Loss: 1.3976826667785645  Training Accuracy: 0.5028740763664246
Epoch: 48  Validation Loss: 1.4098138809204102  Validation Accuracy: 0.5167999863624573
Epoch: 49  Training Loss: 1.3915156126022339  Training Accuracy: 0.5052197575569153
Epoch: 49  Validation Loss: 1.420576810836792  Validation Accuracy: 0.5094000101089478
Epoch: 50  Training Loss: 1.3853501081466675  Training Accuracy: 0.507540762424469
Epoch: 50  Validation Loss: 1.4304229021072388  Validation Accuracy: 0.5127999782562256
Epoch: 51  Training Loss: 1.387136697769165  Training Accuracy: 0.5025308728218079
Epoch: 51  Validation Loss: 1.4339094161987305  Validation Accuracy: 0.5126000046730042
Epoch: 52  Training Loss: 1.388833999633789  Training Accuracy: 0.5052222013473511
Epoch: 52  Validation Loss: 1.4263410568237305  Validation Accuracy: 0.5095999836921692
Epoch: 53  Training Loss: 1.393803596496582  Training Accuracy: 0.5042296648025513
Epoch: 53  Validation Loss: 1.4262335300445557  Validation Accuracy: 0.5127999782562256
Epoch: 54  Training Loss: 1.381976842880249  Training Accuracy: 0.5083629488945007
Epoch: 54  Validation Loss: 1.4254753589630127  Validation Accuracy: 0.5099999904632568
Epoch: 55  Training Loss: 1.3809752464294434  Training Accuracy: 0.5065629482269287
Epoch: 55  Validation Loss: 1.430738091468811  Validation Accuracy: 0.5009999871253967
Epoch: 56  Training Loss: 1.3773362636566162  Training Accuracy: 0.5106370449066162
Epoch: 56  Validation Loss: 1.4245549440383911  Validation Accuracy: 0.5216000080108643
Epoch: 57  Training Loss: 1.3729215860366821  Training Accuracy: 0.5090839266777039
Epoch: 57  Validation Loss: 1.436993956565857  Validation Accuracy: 0.5072000026702881
Epoch: 58  Training Loss: 1.373262882232666  Training Accuracy: 0.5121999979019165
Epoch: 58  Validation Loss: 1.4360151290893555  Validation Accuracy: 0.5113999843597412
Epoch: 59  Training Loss: 1.3662481307983398  Training Accuracy: 0.5138518810272217
Epoch: 59  Validation Loss: 1.4134043455123901  Validation Accuracy: 0.5284000039100647
Epoch: 60  Training Loss: 1.3709661960601807  Training Accuracy: 0.5074321031570435
Epoch: 60  Validation Loss: 1.4314132928848267  Validation Accuracy: 0.5117999911308289
Epoch: 61  Training Loss: 1.367928147315979  Training Accuracy: 0.5132543444633484
Epoch: 61  Validation Loss: 1.432157039642334  Validation Accuracy: 0.5175999999046326
Epoch: 62  Training Loss: 1.3623530864715576  Training Accuracy: 0.5145037174224854
Epoch: 62  Validation Loss: 1.426966905593872  Validation Accuracy: 0.5170000195503235
Epoch: 63  Training Loss: 1.358620524406433  Training Accuracy: 0.516955554485321
Epoch: 63  Validation Loss: 1.4165548086166382  Validation Accuracy: 0.5185999870300293
Epoch: 64  Training Loss: 1.3586307764053345  Training Accuracy: 0.5161629915237427
Epoch: 64  Validation Loss: 1.4213345050811768  Validation Accuracy: 0.5149999856948853
Epoch: 65  Training Loss: 1.3607977628707886  Training Accuracy: 0.511044442653656
Epoch: 65  Validation Loss: 1.417413592338562  Validation Accuracy: 0.5153999924659729
Epoch: 66  Training Loss: 1.3474451303482056  Training Accuracy: 0.5215111374855042
Epoch: 66  Validation Loss: 1.4213569164276123  Validation Accuracy: 0.5278000235557556
Epoch: 67  Training Loss: 1.354224681854248  Training Accuracy: 0.518204927444458
Epoch: 67  Validation Loss: 1.42189359664917  Validation Accuracy: 0.5109999775886536
Epoch: 68  Training Loss: 1.3512665033340454  Training Accuracy: 0.5170221924781799
Epoch: 68  Validation Loss: 1.4186913967132568  Validation Accuracy: 0.5217999815940857
Epoch: 69  Training Loss: 1.3461337089538574  Training Accuracy: 0.5219407677650452
Epoch: 69  Validation Loss: 1.4121999740600586  Validation Accuracy: 0.5181999802589417
Epoch: 70  Training Loss: 1.3421659469604492  Training Accuracy: 0.5197061896324158
Epoch: 70  Validation Loss: 1.4108245372772217  Validation Accuracy: 0.5181999802589417
Epoch: 71  Training Loss: 1.3444583415985107  Training Accuracy: 0.5228074193000793
Epoch: 71  Validation Loss: 1.41634202003479  Validation Accuracy: 0.5185999870300293
Epoch: 72  Training Loss: 1.3449817895889282  Training Accuracy: 0.5209110975265503
Epoch: 72  Validation Loss: 1.4275957345962524  Validation Accuracy: 0.5180000066757202
Epoch: 73  Training Loss: 1.3409414291381836  Training Accuracy: 0.5182889103889465
Epoch: 73  Validation Loss: 1.4420732259750366  Validation Accuracy: 0.5109999775886536
Epoch: 74  Training Loss: 1.3414841890335083  Training Accuracy: 0.5194419622421265
Epoch: 74  Validation Loss: 1.4355376958847046  Validation Accuracy: 0.5156000256538391
Epoch: 75  Training Loss: 1.3376562595367432  Training Accuracy: 0.5237901210784912
Epoch: 75  Validation Loss: 1.4242324829101562  Validation Accuracy: 0.5203999876976013
Epoch: 76  Training Loss: 1.3295972347259521  Training Accuracy: 0.5223555564880371
Epoch: 76  Validation Loss: 1.405861735343933  Validation Accuracy: 0.5253999829292297
Epoch: 77  Training Loss: 1.3330374956130981  Training Accuracy: 0.5250691175460815
Epoch: 77  Validation Loss: 1.4214423894882202  Validation Accuracy: 0.5184000134468079
Epoch: 78  Training Loss: 1.3313744068145752  Training Accuracy: 0.5247012376785278
Epoch: 78  Validation Loss: 1.4102510213851929  Validation Accuracy: 0.5175999999046326
Epoch: 79  Training Loss: 1.3315889835357666  Training Accuracy: 0.5245407819747925
Epoch: 79  Validation Loss: 1.4176775217056274  Validation Accuracy: 0.517799973487854
Epoch: 80  Training Loss: 1.3225574493408203  Training Accuracy: 0.5254345536231995
Epoch: 80  Validation Loss: 1.4319639205932617  Validation Accuracy: 0.5139999985694885
Epoch: 81  Training Loss: 1.3242400884628296  Training Accuracy: 0.5279505848884583
Epoch: 81  Validation Loss: 1.4137903451919556  Validation Accuracy: 0.522599995136261
Epoch: 82  Training Loss: 1.3255712985992432  Training Accuracy: 0.5306000113487244
Epoch: 82  Validation Loss: 1.435032844543457  Validation Accuracy: 0.5117999911308289
Epoch: 83  Training Loss: 1.3170769214630127  Training Accuracy: 0.5308839678764343
Epoch: 83  Validation Loss: 1.4016203880310059  Validation Accuracy: 0.5249999761581421
Epoch: 84  Training Loss: 1.3193508386611938  Training Accuracy: 0.5286123156547546
Epoch: 84  Validation Loss: 1.4103237390518188  Validation Accuracy: 0.5217999815940857
Epoch: 85  Training Loss: 1.3152451515197754  Training Accuracy: 0.5286518931388855
Epoch: 85  Validation Loss: 1.4163219928741455  Validation Accuracy: 0.5188000202178955
Epoch: 86  Training Loss: 1.3148674964904785  Training Accuracy: 0.5287728309631348
Epoch: 86  Validation Loss: 1.4378025531768799  Validation Accuracy: 0.5016000270843506
Epoch: 87  Training Loss: 1.3109859228134155  Training Accuracy: 0.533513605594635
Epoch: 87  Validation Loss: 1.4067258834838867  Validation Accuracy: 0.5289999842643738
Epoch: 88  Training Loss: 1.3146874904632568  Training Accuracy: 0.5284123420715332
Epoch: 88  Validation Loss: 1.4302799701690674  Validation Accuracy: 0.5184000134468079
Epoch: 89  Training Loss: 1.313051462173462  Training Accuracy: 0.5305086374282837
Epoch: 89  Validation Loss: 1.411830186843872  Validation Accuracy: 0.5153999924659729
Epoch: 90  Training Loss: 1.3090218305587769  Training Accuracy: 0.5358197689056396
Epoch: 90  Validation Loss: 1.424660325050354  Validation Accuracy: 0.5153999924659729
Epoch: 91  Training Loss: 1.3053388595581055  Training Accuracy: 0.5351259112358093
Epoch: 91  Validation Loss: 1.4414896965026855  Validation Accuracy: 0.5072000026702881
Epoch: 92  Training Loss: 1.3130396604537964  Training Accuracy: 0.5343357920646667
Epoch: 92  Validation Loss: 1.4312341213226318  Validation Accuracy: 0.5180000066757202
Epoch: 93  Training Loss: 1.3029855489730835  Training Accuracy: 0.5359678864479065
Epoch: 93  Validation Loss: 1.4272007942199707  Validation Accuracy: 0.5054000020027161
Epoch: 94  Training Loss: 1.3100167512893677  Training Accuracy: 0.5318493843078613
Epoch: 94  Validation Loss: 1.4131741523742676  Validation Accuracy: 0.5181999802589417
Epoch: 95  Training Loss: 1.2955403327941895  Training Accuracy: 0.5361382961273193
Epoch: 95  Validation Loss: 1.4214624166488647  Validation Accuracy: 0.5278000235557556
Epoch: 96  Training Loss: 1.2986778020858765  Training Accuracy: 0.5367827415466309
Epoch: 96  Validation Loss: 1.4282993078231812  Validation Accuracy: 0.5220000147819519
Epoch: 97  Training Loss: 1.301589012145996  Training Accuracy: 0.5382863879203796
Epoch: 97  Validation Loss: 1.4261794090270996  Validation Accuracy: 0.5081999897956848
Epoch: 98  Training Loss: 1.29421067237854  Training Accuracy: 0.539158046245575
Epoch: 98  Validation Loss: 1.4398508071899414  Validation Accuracy: 0.5063999891281128
Epoch: 99  Training Loss: 1.2932816743850708  Training Accuracy: 0.5376074314117432
Epoch: 99  Validation Loss: 1.4264060258865356  Validation Accuracy: 0.5126000046730042
Epoch: 100  Training Loss: 1.2903404235839844  Training Accuracy: 0.5398271679878235
Epoch: 100  Validation Loss: 1.4327601194381714  Validation Accuracy: 0.5091999769210815
Epoch: 101  Training Loss: 1.2905559539794922  Training Accuracy: 0.5392296314239502
Epoch: 101  Validation Loss: 1.4231091737747192  Validation Accuracy: 0.525600016117096
Epoch: 102  Training Loss: 1.2896463871002197  Training Accuracy: 0.5397876501083374
Epoch: 102  Validation Loss: 1.4244239330291748  Validation Accuracy: 0.51419997215271
Epoch: 103  Training Loss: 1.2860748767852783  Training Accuracy: 0.5410345196723938
Epoch: 103  Validation Loss: 1.3994592428207397  Validation Accuracy: 0.5275999903678894
Epoch: 104  Training Loss: 1.2878949642181396  Training Accuracy: 0.5408962965011597
Epoch: 104  Validation Loss: 1.4254658222198486  Validation Accuracy: 0.5144000053405762
Epoch: 105  Training Loss: 1.2883950471878052  Training Accuracy: 0.5374963283538818
Epoch: 105  Validation Loss: 1.419774055480957  Validation Accuracy: 0.5135999917984009
Epoch: 106  Training Loss: 1.29094398021698  Training Accuracy: 0.5409308671951294
Epoch: 106  Validation Loss: 1.4175701141357422  Validation Accuracy: 0.510200023651123
Epoch: 107  Training Loss: 1.2864845991134644  Training Accuracy: 0.5406197309494019
Epoch: 107  Validation Loss: 1.433655023574829  Validation Accuracy: 0.5194000005722046
Epoch: 108  Training Loss: 1.2814881801605225  Training Accuracy: 0.54036545753479
Epoch: 108  Validation Loss: 1.4175539016723633  Validation Accuracy: 0.5148000121116638
Epoch: 109  Training Loss: 1.2810258865356445  Training Accuracy: 0.5453011989593506
Epoch: 109  Validation Loss: 1.4411102533340454  Validation Accuracy: 0.5058000087738037
Epoch: 110  Training Loss: 1.2767375707626343  Training Accuracy: 0.5451259016990662
Epoch: 110  Validation Loss: 1.4242937564849854  Validation Accuracy: 0.5152000188827515
Epoch: 111  Training Loss: 1.2797273397445679  Training Accuracy: 0.5410691499710083
Epoch: 111  Validation Loss: 1.4216835498809814  Validation Accuracy: 0.5162000060081482
Epoch: 112  Training Loss: 1.2795100212097168  Training Accuracy: 0.543723464012146
Epoch: 112  Validation Loss: 1.4148575067520142  Validation Accuracy: 0.5238000154495239
Epoch: 113  Training Loss: 1.2840317487716675  Training Accuracy: 0.5433728098869324
Epoch: 113  Validation Loss: 1.4308655261993408  Validation Accuracy: 0.521399974822998
Epoch: 114  Training Loss: 1.2732149362564087  Training Accuracy: 0.5485407710075378
Epoch: 114  Validation Loss: 1.4136226177215576  Validation Accuracy: 0.5184000134468079
Epoch: 115  Training Loss: 1.2762916088104248  Training Accuracy: 0.5458493828773499
Epoch: 115  Validation Loss: 1.4168245792388916  Validation Accuracy: 0.515999972820282
Epoch: 116  Training Loss: 1.2680376768112183  Training Accuracy: 0.5470419526100159
Epoch: 116  Validation Loss: 1.4247390031814575  Validation Accuracy: 0.520799994468689
Epoch: 117  Training Loss: 1.2744451761245728  Training Accuracy: 0.5469456315040588
Epoch: 117  Validation Loss: 1.4247126579284668  Validation Accuracy: 0.5220000147819519
Epoch: 118  Training Loss: 1.2704135179519653  Training Accuracy: 0.5470172762870789
Epoch: 118  Validation Loss: 1.4262444972991943  Validation Accuracy: 0.5210000276565552
Epoch: 119  Training Loss: 1.2662980556488037  Training Accuracy: 0.5457358360290527
Epoch: 119  Validation Loss: 1.4446357488632202  Validation Accuracy: 0.5031999945640564
Epoch: 120  Training Loss: 1.2661399841308594  Training Accuracy: 0.5456172823905945
Epoch: 120  Validation Loss: 1.4410749673843384  Validation Accuracy: 0.5098000168800354
Epoch: 121  Training Loss: 1.2655656337738037  Training Accuracy: 0.5521308779716492
Epoch: 121  Validation Loss: 1.426233172416687  Validation Accuracy: 0.5167999863624573
Epoch: 122  Training Loss: 1.264359474182129  Training Accuracy: 0.5441827178001404
Epoch: 122  Validation Loss: 1.4817806482315063  Validation Accuracy: 0.5126000046730042
Epoch: 123  Training Loss: 1.2586463689804077  Training Accuracy: 0.5473012328147888
Epoch: 123  Validation Loss: 1.4353903532028198  Validation Accuracy: 0.5152000188827515
Epoch: 124  Training Loss: 1.2594853639602661  Training Accuracy: 0.549513578414917
Epoch: 124  Validation Loss: 1.4492143392562866  Validation Accuracy: 0.503600001335144
Epoch: 125  Training Loss: 1.2594447135925293  Training Accuracy: 0.5488987565040588
Epoch: 125  Validation Loss: 1.4323633909225464  Validation Accuracy: 0.5131999850273132
Epoch: 126  Training Loss: 1.255802869796753  Training Accuracy: 0.5518518686294556
Epoch: 126  Validation Loss: 1.4413666725158691  Validation Accuracy: 0.5123999714851379
Epoch: 127  Training Loss: 1.26473069190979  Training Accuracy: 0.5513777732849121
Epoch: 127  Validation Loss: 1.4375121593475342  Validation Accuracy: 0.5157999992370605
Epoch: 128  Training Loss: 1.2542682886123657  Training Accuracy: 0.5540370345115662
Epoch: 128  Validation Loss: 1.4504724740982056  Validation Accuracy: 0.5105999708175659
Epoch: 129  Training Loss: 1.2513189315795898  Training Accuracy: 0.5518099069595337
Epoch: 129  Validation Loss: 1.4205009937286377  Validation Accuracy: 0.5163999795913696
Epoch: 130  Training Loss: 1.2527958154678345  Training Accuracy: 0.5527999997138977
Epoch: 130  Validation Loss: 1.4257056713104248  Validation Accuracy: 0.5249999761581421
Epoch: 131  Training Loss: 1.2562839984893799  Training Accuracy: 0.5535531044006348
Epoch: 131  Validation Loss: 1.4216963052749634  Validation Accuracy: 0.5175999999046326
Epoch: 132  Training Loss: 1.2536559104919434  Training Accuracy: 0.5540444254875183
Epoch: 132  Validation Loss: 1.4638124704360962  Validation Accuracy: 0.5045999884605408
Epoch: 133  Training Loss: 1.2416468858718872  Training Accuracy: 0.5559234619140625
Epoch: 133  Validation Loss: 1.4318691492080688  Validation Accuracy: 0.5138000249862671
Epoch: 134  Training Loss: 1.2484626770019531  Training Accuracy: 0.5525925755500793
Epoch: 134  Validation Loss: 1.4283041954040527  Validation Accuracy: 0.5098000168800354
Epoch: 135  Training Loss: 1.2476145029067993  Training Accuracy: 0.5525259375572205
Epoch: 135  Validation Loss: 1.4192759990692139  Validation Accuracy: 0.5180000066757202
Epoch: 136  Training Loss: 1.2428950071334839  Training Accuracy: 0.5547900795936584
Epoch: 136  Validation Loss: 1.4173896312713623  Validation Accuracy: 0.5175999999046326
Epoch: 137  Training Loss: 1.2474184036254883  Training Accuracy: 0.5535407662391663
Epoch: 137  Validation Loss: 1.4325700998306274  Validation Accuracy: 0.5088000297546387
Epoch: 138  Training Loss: 1.2506657838821411  Training Accuracy: 0.5534691214561462
Epoch: 138  Validation Loss: 1.4318729639053345  Validation Accuracy: 0.5138000249862671
Epoch: 139  Training Loss: 1.246146321296692  Training Accuracy: 0.5534247159957886
Epoch: 139  Validation Loss: 1.4452099800109863  Validation Accuracy: 0.5041999816894531
Epoch: 140  Training Loss: 1.2379581928253174  Training Accuracy: 0.5580024719238281
Epoch: 140  Validation Loss: 1.4210954904556274  Validation Accuracy: 0.5175999999046326
Epoch: 141  Training Loss: 1.248124599456787  Training Accuracy: 0.5566123127937317
Epoch: 141  Validation Loss: 1.4428008794784546  Validation Accuracy: 0.506600022315979
Epoch: 142  Training Loss: 1.244733452796936  Training Accuracy: 0.5554099082946777
Epoch: 142  Validation Loss: 1.4461289644241333  Validation Accuracy: 0.5077999830245972
Epoch: 143  Training Loss: 1.2403653860092163  Training Accuracy: 0.5562642216682434
Epoch: 143  Validation Loss: 1.4609843492507935  Validation Accuracy: 0.5072000026702881
Epoch: 144  Training Loss: 1.2339286804199219  Training Accuracy: 0.5589678883552551
Epoch: 144  Validation Loss: 1.4439287185668945  Validation Accuracy: 0.5037999749183655
Epoch: 145  Training Loss: 1.2368900775909424  Training Accuracy: 0.5580074191093445
Epoch: 145  Validation Loss: 1.4312807321548462  Validation Accuracy: 0.5162000060081482
Epoch: 146  Training Loss: 1.2351893186569214  Training Accuracy: 0.5583851933479309
Epoch: 146  Validation Loss: 1.4269946813583374  Validation Accuracy: 0.5206000208854675
Epoch: 147  Training Loss: 1.2268378734588623  Training Accuracy: 0.5605506300926208
Epoch: 147  Validation Loss: 1.4191830158233643  Validation Accuracy: 0.5231999754905701
Epoch: 148  Training Loss: 1.231486201286316  Training Accuracy: 0.5596321225166321
Epoch: 148  Validation Loss: 1.4334315061569214  Validation Accuracy: 0.5120000243186951
Epoch: 149  Training Loss: 1.235612392425537  Training Accuracy: 0.5584049224853516
Epoch: 149  Validation Loss: 1.424896001815796  Validation Accuracy: 0.5175999999046326

Process finished with exit code 0
